# Launching an experiment

An optimization experiment is defined by the combination of:

* **A component** (see section [registering a component](registering.md)) and its parametric space (the possible values taken by the optimizer)

* **An application**: defined as a file that can be launched through Slurm

* **An optimization heuristic**: an optimization algorithm, a number of exploration and exploitation step, a possible pruning strategy, a possible noise reduction strategy. More details on black-box optimization are available [here](../bbo/heuristics.md).

## Launching an experiment through the Web interface

The preferred way of launching an optimization experiment is through the Web interface, by filling out the menu available at the path `/create`.

### Experiment arguments

* **The component and its parametric space**: the component to optimize, among the registered ones, as well as the parametric space, defined through a min, max and a step value.

* **The application**: the application to optimize is written as a shell file, directly through the Web interface.

* **Number of iterations**: the number of exploration iteration must be specified as an integer value.

### Setting up the optimizer

- **Pruning strategies**: this option stops **jobs that take longer than a certain threshold**, either longer than **the default parametrization** or **the current median execution time**.

- **Noise reduction strategies**: this option resamples parametrization a certain number of times to smoothes out possible noise. The resampling can be **static** (i.e. fixed number of resamples) or **dynamic** (i.e. the parametrization is repeated until the 95% confidence interval is below a fixed threshold). The fitness aggregation function is the transformation applied to execution times corresponding to the same parametrization (it can be either the **mean** or **median**).

- **Initialization steps**: this field specifies the number of parametrization sampled using a *Latin Hypercube Design* before starting the optimization heuristic. 

- **Optimization heuristic**: three possible heuristics (surrogate models, genetic algorithms and simulated annealing) can be chosen, as well as their different hyperparameters. For a detailed overview of the available heuristics and their hyperparametrization, refer to this section [here](../bbo/heuristics.md).

## Launching an experiment through the command line interface

### The shaman-optimize command

!!! tip
    Launching an experiment through the command line interface gives access to more options to tune the optimizer, but it is also riskier because there is no configuration check before running the experiment. Beware !

Launching an optimization experiment can also be done through the command line interface `shaman-optimize`.

``` shell
shaman-optimize --help

Usage: shaman-optimize [OPTIONS]

  Run an optimization experiment.

Options:
  --component-name TEXT      The name of the component to tune  [required]
  --nbr-iteration INTEGER    The maximal number of iterations to run the
                             experiment for.  [required]

  --sbatch-file TEXT         The path to the sbatch file  [required]
  --experiment-name TEXT     The name to give the experiment  [required]
  --configuration-file TEXT  The path to the configuration file  [required]
  --sbatch-dir TEXT          The directory to store the sbatch
  --slurm-dir TEXT           The directory to write the slurm outputs
  --result-file TEXT         The path to the result file.
  --help                     Show this message and exit.
```

It requires:

* **The application to optimize**: a file that can be submitted with the *sbatch* command.

* **The number of iterations**: the allocated number of iterations for the experiment.

* **Experiment name**: the name of the experiment for re-identification in the Web interface

* **Configuration file**: the configuration file of the experiment, see next section.

* **Directory to store the sbatch**: an optional argument to indicate where the sbatch generated by shaman must be stored. 

* **Directory to store the slurm outputs**: an optional argument to indicate where to store the slurm outputs.

### Writing a configuration file

SHAMan's configuration file comes with five sections and is written using a `yaml` format:

- `experiment`: contains information about the experiment.
  *Possible options*: 
    - `default_first`: set to True if the first parameter tested by the optimizer

- `bbo`: parametrizes the optimizer. The possible options are the **different arguments taken by the optimizer**. All the arguments described in the file will be passed as *kwargs* of the `BBOptimizer` class (see section [stand-alone optimization](..\bbo\introduction.md) of the documentation).

- `noise_reduction`: parametrizes the noise reduction features of the optimizer. The possible arguments are the different noise reduction strategies available in `bbo`, as well as their specific *kwargs*. For more details on how to use noise reduction with `bbo`, see [section](..\bbo\noise-reduction.md).

- `pruning`: parametrizes the pruning strategy features of the optimizer (see [section](..\bbo\pruning-strategies.md) for more details).
  *Possible options*:
    - `max_step_duration`: the maximum elapsed time before stopping the parametrization. Can either be:
        - A numpy estimator (for example, `numpy.median`, `numpy.mean`, *etc*). Runs that go above the value of the estimator computed on the already tested execution times are interrupted.
        - A float value (for example, 5), which corresponds to an elapsed time in seconds
        - The `default` string, which corresponds to stopping runs that take longer than the default value. The option **default_first** in the `experiment` section must be set to `True`.

- `components`: the selected component and the defined parametric grid, using the `min`, `max` and `step` format. 

An example of a configuration file is written below: 

``` yaml
experiment:
  default_first: True

bbo:
  heuristic: genetic_algorithm
  initial_sample_size: 2
  selection_method: bbo.heuristics.genetic_algorithm.selections.tournament_pick
  crossover_method: bbo.heuristics.genetic_algorithm.crossover.single_point_crossover
  mutation_method: bbo.heuristics.genetic_algorithm.mutations.mutate_chromosome_to_neighbor
  pool_size: 5
  mutation_rate: 0.4
  elitism: False

noise_reduction:
  resampling_policy: simple_resampling
  nbr_resamples: 3
  fitness_aggregation: simple_fitness_aggregation
  estimator: numpy.median

pruning:
  max_step_duration: numpy.median

components:
  component_1:
    param_1:
      min: 1
      max: 20
      step: 1
    param_2:
      min: 1
      max: 15
      step: 3
```

This example configuration file launches an experiment which:

* Runs the default parametrization first
* Uses genetic algorithms (tournament pick, single point crossover, random walk for mutation)
* Uses simple resampling, with 3 resampling per parametrization, and the median as an estimator for parametrization with the same parametrization.
* Uses pruning and stops every run that takes longer than the median measured on the data points.
* Uses `component_1` and `param_1` can take any value from 1 to 20, while `param_2` can take any value from 1 to 15 but with an interval of 3 between each value.


## Vizualizing an experiment

Once the experiment has been launched through either of the two methods described above, it can be vizualized in the Web interface, where different statistics are displayed. If the experiment is still running, the evolution is available in real-time.